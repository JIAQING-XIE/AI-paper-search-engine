{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a05a7788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-rake in /Users/jw/opt/anaconda3/envs/ttds/lib/python3.8/site-packages (1.5.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-rake #or pip3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63d2ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RAKE\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cc8752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_dir = \"SmartStoplist.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a934bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_object = RAKE.Rake(stop_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8789781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple(tup):\n",
    "    tup.sort(key = lambda x: x[1])\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63b03b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = \"AI Platform Pipelines has two major parts: (1) the infrastructure for deploying and running structured AI workflows that are integrated with Google Cloud Platform services and (2) the pipeline tools for building, debugging, and sharing pipelines and components. The service runs on a Google Kubernetes cluster that’s automatically created as a part of the installation process, and it’s accessible via the Cloud AI Platform dashboard. With AI Platform Pipelines, developers specify a pipeline using the Kubeflow Pipelines software development kit (SDK), or by customizing the TensorFlow Extended (TFX) Pipeline template with the TFX SDK. This SDK compiles the pipeline and submits it to the Pipelines REST API server, which stores and schedules the pipeline for execution.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "138cd830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('installation process', 4.0),\n",
       " ('tensorflow extended', 4.0),\n",
       " ('sharing pipelines', 5.4),\n",
       " ('google kubernetes cluster', 9.5),\n",
       " ('ai platform pipelines', 10.4),\n",
       " ('google cloud platform services', 15.0),\n",
       " ('cloud ai platform dashboard', 15.0),\n",
       " ('pipelines rest api server', 15.4),\n",
       " ('running structured ai workflows', 15.5),\n",
       " ('kubeflow pipelines software development kit', 23.4)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = Sort_Tuple(rake_object.run(subtitles))[-10:]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41982c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Knowledge Graph Completion (KGC) has been proposed to improve Knowledge Graphs by filling in missing connections via link prediction or relation extraction. One of the main difficulties for KGC is a low resource problem. Previous approaches assume sufficient training triples to learn versatile vectors for entities and relations, or a satisfactory number of labeled sentences to train a competent relation extraction model. However, low resource relations are very common in KGs, and those newly added relations often do not have many known samples for training. In this work, we aim at predicting new facts under a challenging setting where only limited training instances are available. We propose a general framework called Weighted Relation Adversarial Network, which utilizes an adversarial procedure to help adapt knowledge/features learned from high resource relations to different but related low resource relations. Specifically, the framework takes advantage of a relation discriminator to distinguish between samples from different relations, and help learn relation-invariant features more transferable from source relations to target relations. Experimental results show that the proposed approach outperforms previous methods regarding low resource settings for both link prediction and relation extraction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a6eb1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('proposed approach outperforms previous methods', 23.0),\n",
       " ('adapt knowledge/features learned', 15.333333333333334),\n",
       " ('learn relation-invariant features', 14.3),\n",
       " ('competent relation extraction model', 13.466666666666667),\n",
       " ('related low resource relations', 12.825),\n",
       " ('learn versatile vectors', 9.5),\n",
       " ('low resource settings', 9.45),\n",
       " ('low resource problem', 9.45),\n",
       " ('improve knowledge graphs', 9.333333333333334),\n",
       " ('knowledge graph completion', 9.333333333333334)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = Sort_Tuple(rake_object.run(a))[-10:]\n",
    "\n",
    "keywords = keywords[::-1]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29d8f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jw/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cf3f6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('proposed', 'VBN'),\n",
       "  ('approach', 'NN'),\n",
       "  ('outperforms', 'VBZ'),\n",
       "  ('previous', 'JJ'),\n",
       "  ('methods', 'NNS')],\n",
       " [('adapt', 'JJ'), ('knowledge/features', 'NNS'), ('learned', 'VBD')],\n",
       " [('learn', 'JJ'), ('relation-invariant', 'JJ'), ('features', 'NNS')],\n",
       " [('competent', 'JJ'),\n",
       "  ('relation', 'NN'),\n",
       "  ('extraction', 'NN'),\n",
       "  ('model', 'NN')],\n",
       " [('related', 'VBN'), ('low', 'JJ'), ('resource', 'NN'), ('relations', 'NNS')],\n",
       " [('learn', 'NN'), ('versatile', 'NN'), ('vectors', 'NNS')],\n",
       " [('low', 'JJ'), ('resource', 'NN'), ('settings', 'NNS')],\n",
       " [('low', 'JJ'), ('resource', 'NN'), ('problem', 'NN')],\n",
       " [('improve', 'VB'), ('knowledge', 'NN'), ('graphs', 'NN')],\n",
       " [('knowledge', 'NN'), ('graph', 'NN'), ('completion', 'NN')]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "[pos_tag(word_tokenize(k[0] )) for k in keywords ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b57efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "jar = \"./stanford-postagger.jar\"\n",
    "model = \"./english-bidirectional-distsim.tagger\"\n",
    "pos_tagger = StanfordPOSTagger(model, jar, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee0bc94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('proposed', 'VBN'),\n",
       "  ('approach', 'NN'),\n",
       "  ('outperforms', 'VBZ'),\n",
       "  ('previous', 'JJ'),\n",
       "  ('methods', 'NNS')],\n",
       " [('adapt', 'VB'), ('knowledge/features', 'NNS'), ('learned', 'VBN')],\n",
       " [('learn', 'VB'), ('relation-invariant', 'JJ'), ('features', 'NNS')],\n",
       " [('competent', 'JJ'),\n",
       "  ('relation', 'NN'),\n",
       "  ('extraction', 'NN'),\n",
       "  ('model', 'NN')],\n",
       " [('related', 'VBN'), ('low', 'JJ'), ('resource', 'NN'), ('relations', 'NNS')],\n",
       " [('learn', 'VB'), ('versatile', 'JJ'), ('vectors', 'NNS')],\n",
       " [('low', 'JJ'), ('resource', 'NN'), ('settings', 'NNS')],\n",
       " [('low', 'JJ'), ('resource', 'NN'), ('problem', 'NN')],\n",
       " [('improve', 'VB'), ('knowledge', 'NN'), ('graphs', 'NNS')],\n",
       " [('knowledge', 'NN'), ('graph', 'NN'), ('completion', 'NN')]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pos_tagger.tag(word_tokenize(k[0])) for k in keywords ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b40590cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import StanfordTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf2d4636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knowledge graph completion',\n",
       " 'low resource relations',\n",
       " 'relation-invariant features',\n",
       " 'competent relation extraction model',\n",
       " 'approach previous methods',\n",
       " 'versatile vectors',\n",
       " 'knowledge graphs',\n",
       " 'low resource problem',\n",
       " 'low resource settings']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for keyword in keywords:\n",
    "    postag = pos_tagger.tag(word_tokenize(keyword[0]))\n",
    "    k = []\n",
    "    for (a, b) in postag:\n",
    "        if not 'V' in b[0]: # and not 'J' in b[0]:\n",
    "            k.append(a)\n",
    "    if len(k)>1:\n",
    "        res.append(\" \".join(k))\n",
    "\n",
    "res = list(set(res))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b82a8323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i walk'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "a = \"I walked\"\n",
    "a = \" \".join([stemmer.stem(aa) for aa in a.split(\" \")])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36f7fce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knowledge graph completion',\n",
       " 'low resource relations',\n",
       " 'relation-invariant features',\n",
       " 'competent relation extraction model',\n",
       " 'approach previous methods',\n",
       " 'versatile vectors',\n",
       " 'knowledge graphs',\n",
       " 'low resource problem',\n",
       " 'low resource settings']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "843e5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemsentence(arr):\n",
    "    return  \" \".join([stemmer.stem(aa) for aa in arr.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60c015dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knowledge graph completion',\n",
       " 'low resource relations',\n",
       " 'relation-invariant features',\n",
       " 'competent relation extraction model',\n",
       " 'approach previous methods',\n",
       " 'versatile vectors',\n",
       " 'low resource problem',\n",
       " 'low resource settings']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = res.copy()\n",
    "for i in range(len(res)):\n",
    "    r = res[i]\n",
    "    others = res[:i] + res[i+1:]\n",
    "    r2 = \"\".join(stemsentence(r))\n",
    "    others = \"\".join([stemsentence(other) for other in others])\n",
    "    if r2 in others:\n",
    "        res2.remove(r)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4977e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65db62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
