**Machine_Learning_Pipeline

***TODO:
***1. Manage all csv files of collected paper into one csv file
keyword extractor for paper abstract and search engine indexer
Grammar corrector loaded to search engine: https://github.com/PrithivirajDamodaran/Gramformer 

***2. Spelling corrector: https://github.com/filyp/autocorrect

***3. Web translator
***4. Hierarchy of information:
          a. wordnet: https://wordnet.princeton.edu/ 
          b. similarity: https://github.com/MichelDeudon/variational-siamese-network,
                         https://github.com/MIR-MU/regularized-embeddings
          c.other papers: https://paperswithcode.com/search?q_meta=&q_type=&q=From+Word+Embeddings+to+Document+Distances 

***Ideas:
Machine Learning:
Self-supervised/ Semi-supervised learning: clustering, classification: PCA low dimensionality clustering
prediction, recommendation: hierarchy of information (similar to grammar tree)
words/grammar auto-correction
text summarization based on paper abstracts with Seq2Seq, LSTM (maybe?)
Translate over pages to several languages:
Translate paper from English to Chinese
Search with Chinese words and refer to papers or keywords in English

Possible Metrics to evaluate the search engine system(Maybe compare with google scholar, similarity)

